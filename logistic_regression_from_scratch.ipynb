{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 Days of ML Code Challenge Day 34\n",
    "\n",
    "Implementing Logistic Regression from Scratch\n",
    "\n",
    "Training a Logistic Regression Model using only numpy matrix operations (Labels are made on function of input data added to Gaussian noise). Prediction accuracy is around 97.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(X):\n",
    "    y=[]\n",
    "    for i in range(X.shape[0]):\n",
    "        noise = np.random.randn(X.shape[0])\n",
    "        if(X[i,0]+3*X[i,1]-20 + noise[i]>0):  #Linear Function added with Gaussian Noise\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return np.array(y).reshape(len(y),1)\n",
    "\n",
    "def weighted_sum(X,w,b):\n",
    "    return np.dot(X,w)+b\n",
    "        \n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "def sigmoid_matrix(matrix):\n",
    "    sigm_matrix = np.zeros(matrix.shape)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        sigm_matrix[i,:] = [sigmoid(x) for x in matrix[i,:]]\n",
    "    return sigm_matrix\n",
    "\n",
    "def log(x):\n",
    "    if(x>0):\n",
    "        return math.log(x)\n",
    "    else:\n",
    "        return -999\n",
    "\n",
    "def log_matrix(matrix):\n",
    "    ln_matrix = np.zeros(matrix.shape)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        ln_matrix[i,:] = [log(x) for x in matrix[i,:]]\n",
    "    return ln_matrix\n",
    "\n",
    "def cost_function(w,b,X,y):\n",
    "    z = weighted_sum(X,w,b)\n",
    "    h = sigmoid_matrix(z)\n",
    "    w = np.array(w)\n",
    "    cost = (-1/y.shape[0])*(np.sum(y*log_matrix(h)+(1-y)*log_matrix(1-h)))\n",
    "    return cost\n",
    "\n",
    "# def approx_grad(w,b,X,y,eps= 1e-10):\n",
    "#     dw0 = (cost_function([w[0]+eps,w[1]],b,X,y) - cost_function([w[0]+eps,w[1]],b,X,y))/(2*eps)\n",
    "#     dw1 = (cost_function([w[0],w[1]+eps],b,X,y) - cost_function([w[0],w[1]-eps],b,X,y))/(2*eps)\n",
    "#     db = (cost_function(w,b+eps,X,y) - cost_function(w,b-eps,X,y))/(2*eps)\n",
    "#     return np.array(dw0,dw1),db\n",
    "\n",
    "def gradient(w,b,X,y):\n",
    "    n = X.shape[0]\n",
    "    dw = (-1/n)*np.dot(X.transpose(),(y-sigmoid_matrix(weighted_sum(X,w,b))))\n",
    "    db = (-1/n)*np.sum(y-sigmoid_matrix(weighted_sum(X,w,b)))\n",
    "    return dw,db\n",
    "\n",
    "def gradient_descent(w,b,dw,db,alpha=0.01):\n",
    "    w = w - alpha * dw\n",
    "    b = b - alpha * db\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 Cost:  2.345254523966431\n",
      "100 0 Cost:  0.05586870817436407\n",
      "200 0 Cost:  0.05475552644877253\n",
      "300 0 Cost:  0.05453869557299486\n",
      "400 0 Cost:  0.05450438399790014\n",
      "500 0 Cost:  0.054516711023463116\n",
      "600 0 Cost:  0.05453920097444544\n",
      "700 0 Cost:  0.05456099983001336\n",
      "800 0 Cost:  0.05457918008048693\n",
      "900 0 Cost:  0.05459342868242879\n"
     ]
    }
   ],
   "source": [
    "m=10000\n",
    "X = np.random.uniform(0,10,(m,2))\n",
    "y = np.array(my_func(X)).reshape(X.shape[0],1)\n",
    "w = np.random.rand(2,1)\n",
    "b = np.random.rand(1,1)\n",
    "\n",
    "alpha = 1\n",
    "mm = 128\n",
    "epochs = int(m/mm)\n",
    "\n",
    "for j in range(1000):\n",
    "    for i in range(epochs):\n",
    "        a = X[i*mm:(i+1)*mm,:]\n",
    "        yi = y[i*mm:(i+1)*mm,:]\n",
    "        if(j%100==0 and i==0):\n",
    "            print(j,i,\"Cost: \", cost_function(w,b,a,yi))        \n",
    "        dw,db = gradient(w,b,a,yi)\n",
    "        w,b = gradient_descent(w,b,dw,db,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.89741533] [5.79199842] [-38.36056414] \n",
      "\n",
      "Accuracy: 97.4 %\n"
     ]
    }
   ],
   "source": [
    "print(w[0],w[1],b[0],'\\n')\n",
    "X = np.random.uniform(0,10,(1000,2))\n",
    "y = my_func(X)\n",
    "z = np.dot(X,w)+b\n",
    "\n",
    "score = (1000 - np.sum(abs(y-sigmoid_matrix(z).round())))/10\n",
    "print(\"Accuracy:\",score,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
