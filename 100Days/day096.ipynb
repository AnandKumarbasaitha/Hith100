{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"ltr\" style=\"text-align: left;\" trbidi=\"on\">\n",
    "<h2 style=\"text-align: left;\">\n",
    "100 Days of ML Day 96</h2>\n",
    "<h2 style=\"text-align: left;\">\n",
    "Preprocessing, POS Tagging, Chunking</h2>\n",
    "Implemented Preprocessing Methods like Tokenization, Stemming and Stopword Removal. Watched lectures from sentdex's NLP with Python and NLTK course on Youtube.<br />\n",
    "<br />\n",
    "Code: <a href=\"https://github.com/hithesh111/Hith100/blob/master/100Days/day096.ipynb\">https://github.com/hithesh111/Hith100/blob/master/100Days/day096.ipynb</a><br />\n",
    "<br />\n",
    "Videos:<br />\n",
    "<a href=\"https://www.youtube.com/watch?v=6j6M2MtEqi8&amp;list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&amp;index=4\">Part of Speech Tagging - Natural Language Processing With Python and NLTK p.4</a><br />\n",
    "<a href=\"https://www.youtube.com/watch?v=imPpT2Qo2sk&amp;list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&amp;index=5\">Chunking - Natural Language Processing With Python and NLTK p.5</a><br />\n",
    "<a href=\"https://www.youtube.com/watch?v=EymPQgCtcAE&amp;list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&amp;index=6\">Chinking - Natural Language Processing With Python and NLTK p.6</a></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there.', \"I'm in the empire business!\", \"What's west of Westeros?\"]\n",
      "['Hello', 'there', '.', 'I', \"'m\", 'in', 'the', 'empire', 'business', '!', 'What', \"'s\", 'west', 'of', 'Westeros', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello there. I'm in the empire business! What's west of Westeros?\"\n",
    "words = word_tokenize(text)\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "there\n",
      ".\n",
      "I\n",
      "'m\n",
      "in\n",
      "the\n",
      "empir\n",
      "busi\n",
      "!\n",
      "what\n",
      "'s\n",
      "west\n",
      "of\n",
      "westero\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"needn't\", 'her', 'does', 'i', 'because', 'against', 'same', \"haven't\", \"isn't\", 's', 'wouldn', 'their', 'did', 'nor', 'out', 'what', \"you're\", 'at', 'those', \"doesn't\", 'the', 'through', 'of', \"that'll\", 'are', 'being', 'he', \"couldn't\", 'having', 'during', 'needn', 'off', \"wouldn't\", 'from', 'how', 'further', 'over', 'between', \"aren't\", 'just', 'which', 'yours', 'd', \"shan't\", 'you', 'whom', 'in', 'before', 'y', 'ourselves', 'him', 'by', 'weren', 'been', 'there', 'wasn', 'couldn', 'no', 'too', 'hasn', 'mightn', 'for', 'don', 'mustn', 'if', 'be', 'now', 'some', 'them', 'shouldn', 'these', 'after', 'haven', 'each', 'herself', 'it', 'ain', 'so', \"wasn't\", 'we', 'his', \"don't\", 'most', 'themselves', 't', \"weren't\", 'who', 'yourself', \"mustn't\", 'isn', \"it's\", 'than', 'doing', 'above', \"won't\", 'any', 'why', 'a', 'is', 'up', 'our', 'hadn', \"you'll\", 'my', \"hasn't\", 'down', 'm', 'with', 'then', 'on', 'or', 'have', 'into', \"should've\", 'all', 'shan', 'am', 'below', 'under', 'when', 'll', 'both', 'were', 'as', \"you'd\", 'and', 'won', 'was', \"didn't\", 'do', 'once', 'she', 'theirs', 'doesn', 'while', 'will', 'that', 'such', 'itself', 'only', 'o', 'your', 'they', 'has', 'not', 'own', 'until', 'an', 'yourselves', 'its', 'didn', \"hadn't\", 'can', 'ours', 'myself', 'here', 'about', 'this', 'more', 'again', 'but', 'where', 'aren', 'should', 'other', 'to', 've', 'few', 're', 'very', \"mightn't\", 'ma', \"shouldn't\", 'me', \"you've\", \"she's\", 'hers', 'himself', 'had'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1  = \"Manchester United is delighted to confirm the signing of Bruno Fernandes from Sporting Clube de Portugal. Bruno signs on a five-and-a-half year contract, with an option to extend for a further year. The 25-year-old Portuguese international has contributed 63 goals and 52 assists in 137 appearances for Sporting Clube de Portugal. He has made 19 senior appearances for his country and was part of the successful squad that won the UEFA Nations League in 2019.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manchest\n",
      "unit\n",
      "delight\n",
      "confirm\n",
      "sign\n",
      "bruno\n",
      "fernand\n",
      "sport\n",
      "clube\n",
      "de\n",
      "portug\n",
      ".\n",
      "bruno\n",
      "sign\n",
      "five-and-a-half\n",
      "year\n",
      "contract\n",
      ",\n",
      "option\n",
      "extend\n",
      "year\n",
      ".\n",
      "the\n",
      "25-year-old\n",
      "portugues\n",
      "intern\n",
      "contribut\n",
      "63\n",
      "goal\n",
      "52\n",
      "assist\n",
      "137\n",
      "appear\n",
      "sport\n",
      "clube\n",
      "de\n",
      "portug\n",
      ".\n",
      "He\n",
      "made\n",
      "19\n",
      "senior\n",
      "appear\n",
      "countri\n",
      "part\n",
      "success\n",
      "squad\n",
      "uefa\n",
      "nation\n",
      "leagu\n",
      "2019\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "words1 = word_tokenize(text1)\n",
    "for w in words1:\n",
    "    if(w not in stop_words):\n",
    "        print(ps.stem(w))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
